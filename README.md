# ğŸ  Boston Housing Price Prediction â€” XGBoost (End-to-End ML Project)

Este proyecto implementa un flujo completo de **Machine Learning para regresiÃ³n**, utilizando el dataset de **Boston Housing**, con un entrenamiento de modelo **XGBoost tunado**, un **pipeline modular en Python** y una **aplicaciÃ³n web en Streamlit** para probar predicciones en tiempo real.

El objetivo final es predecir el valor medio de viviendas (`medv`) en miles de dÃ³lares.

---

## ğŸ“Œ **1. Objetivo del proyecto**

Construir un proyecto **end-to-end** que incluya:

âœ” ExploraciÃ³n y anÃ¡lisis de datos (EDA)  
âœ” IngenierÃ­a de caracterÃ­sticas  
âœ” SelecciÃ³n de variables  
âœ” Entrenamiento de modelos tradicionales y de boosting  
âœ” BÃºsqueda de hiperparÃ¡metros (GridSearchCV / RandomizedSearchCV)  
âœ” ValidaciÃ³n cruzada  
âœ” Pipeline modular en `.py`  
âœ” Despliegue de una app en Streamlit  

---

## ğŸ“ **2. Estructura del proyecto**

```bash
â”œâ”€ data/
â”‚  â””â”€ bostonvivienda.csv
â”œâ”€ notebooks/
â”‚  â”œâ”€ 01_EDA.ipynb
â”‚  â””â”€ 02_Modelado.ipynb
â”œâ”€ src/
â”‚  â”œâ”€ components/
â”‚  â”‚  â”œâ”€ data_ingestion.py
â”‚  â”‚  â”œâ”€ data_transformation.py
â”‚  â”‚  â””â”€ model_trainer.py
â”‚  â”œâ”€ pipeline/
â”‚  â”‚  â”œâ”€ training_pipeline.py
â”‚  â”‚  â””â”€ predict_pipeline.py
â”‚  â”œâ”€ utils.py
â”‚  â”œâ”€ exception.py
â”‚  â””â”€ logger.py
â”œâ”€ artifacts/
â”‚  â”œâ”€ raw.csv
â”‚  â”œâ”€ train.csv
â”‚  â”œâ”€ test.csv
â”‚  â”œâ”€ preprocessor.pkl
â”‚  â”œâ”€ features.pkl
â”‚  â””â”€ model_xgb_tuned.pkl
â”œâ”€ app.py
â”œâ”€ requirements.txt
â””â”€ README.md
```

## ğŸ“Š **3. Dataset â€” Boston Housing**

Cada fila representa una zona residencial en Boston.

Variables principales:

| Variable | DescripciÃ³n                             |
| -------- | --------------------------------------- |
| crim     | Tasa de criminalidad                    |
| zn       | % zona residencial                      |
| indus    | % acres no comerciales                  |
| nox      | Ã“xidos de nitrÃ³geno                     |
| rm       | NÂº promedio de habitaciones             |
| edad     | % viviendas antiguas                    |
| dis      | Distancia ponderada a centros de empleo |
| rad      | Ãndice de accesibilidad radial          |
| impuesto | Tasa impositiva                         |
| ptratio  | Ratio alumno/profesor                   |
| negro    | Ãndice poblaciÃ³n negra                  |
| lstat    | % poblaciÃ³n con bajo estatus            |
| **medv** | **Valor medio de vivienda (target)**    |

---

## ğŸ” **4. EDA â€“ Hallazgos principales**

El anÃ¡lisis exploratorio incluyÃ³:

* Distribuciones, histogramas, boxplots
* Medidas estadÃ­sticas: media, mediana, CV, asimetrÃ­a, curtosis
* DetecciÃ³n de outliers por IQR
* Correlaciones y mapa de calor
* RelaciÃ³n entre cada predictor y el target

Insights clave

* Fuerte relaciÃ³n negativa:
    * lstat vs. medv
    * Mayor pobreza â†’ menor precio de vivienda.

* Fuerte relaciÃ³n positiva:
    * rm vs. medv
    * MÃ¡s habitaciones â†’ mayor valor.

* Variables altamente correlacionadas entre sÃ­:
    * nox, indus, rad, impuesto

* Variables con fuerte asimetrÃ­a:
    * crim, zn, lstat

ğŸ”¹ El dataset contiene varios outliers naturales â€” no se eliminaron para mantener consistencia histÃ³rica.

---

## ğŸ§ª **5. IngenierÃ­a de Variables**

Para mejorar la simetrÃ­a, estabilizar la varianza y capturar relaciones no lineales, se aplicaron:

```python
lstat_log      = log1p(lstat)
crim_log       = log1p(crim)
contaminacion  = nox * indus
zn_log         = log1p(zn)
medv_log       = log1p(medv)
```

âœ” Se eligiÃ³ trabajar con medv_log como target transformado.
âœ” Luego se revierte usando exp(pred) - 1.

---

## ğŸ§¬ **6. SelecciÃ³n de Variables**

* Se utilizÃ³ una combinaciÃ³n de:
* CorrelaciÃ³n con el target
* VIF (multicolinealidad)
* Interpretabilidad
* Pruebas de modelado

**Variables finales seleccionadas:**

* lstat_log  
* crim_log  
* contaminacion  
* zn_log

Estas 4 variables lograron capturar >80% del poder predictivo del modelo original.

---

## ğŸ¤– **7. Modelado y EvaluaciÃ³n**

Se probaron mÃºltiples modelos:

* Linear Regression
* Ridge / Lasso / ElasticNet
* RandomForest
* XGBoost (mejor modelo)

ğŸ”¥ **MÃ©tricas obtenidas (test)**

| Modelo            | MAE       | RMSE      | RÂ²       |
| ----------------- | --------- | --------- | -------- |
| Linear Regression | 0.147     | 0.207     | 0.69     |
| Ridge             | 0.147     | 0.207     | 0.69     |
| RandomForest      | 0.127     | 0.169     | 0.79     |
| **XGBoost Tuned** | **0.125** | **0.170** | **0.79** |


---

## ğŸ›  **8. Tuning de HiperparÃ¡metros (GridSearchCV)**

Mejores hiperparÃ¡metros encontrados:

```python
{
 'n_estimators': 800,
 'max_depth': 5,
 'learning_rate': 0.01,
 'subsample': 0.7,
 'colsample_bytree': 0.6,
 'min_child_weight': 7,
 'gamma': 0
}
```

âœ” Aumento de performance

âœ” ReducciÃ³n de overfitting

âœ” Mejor estabilidad entre folds de validaciÃ³n cruzada

---

## ğŸ“¦ **9. Pipeline en scripts (.py)**

**data_ingestion.py**
* Lee dataset
* Crea raw/train/test
* Loguea eventos

**data_transformation.py**
* Aplica feature engineering
* Estandariza variables
* Guarda scaler y lista de features

**model_trainer.py**
* Entrena XGBoost tunado
* EvalÃºa mÃ©tricas RÂ², RMSE, MAE
* Guarda modelo final

**training_pipeline.py**
* Orquesta todo el proceso:
    * Ingesta â†’ TransformaciÃ³n â†’ Entrenamiento â†’ Guardado de artifacts

**predict_pipeline.py**
* Feature engineering para nuevos datos
* Escalamiento
* PredicciÃ³n
* ReversiÃ³n logarÃ­tmica

---

## ğŸŒ **10. AplicaciÃ³n Web â€” Streamlit**

La app permite ingresar 12 variables y devuelve el precio estimado.

**Ejecutar aplicaciÃ³n:**

```bash
streamlit run app.py
```

Â¿QuÃ© incluye?

âœ” Formulario intuitivo

âœ” â€œTarjetaâ€ con resultado

âœ” Expander con datos usados

âœ” ExplicaciÃ³n del modelo

âœ” UI moderna

---

## âš™ï¸ **11. CÃ³mo ejecutar el proyecto**
1ï¸âƒ£ **Crear entorno**

```bash
conda create -p venv python=3.8 -y
conda activate venv
```

2ï¸âƒ£ **Instalar dependencias**

```bash
pip install -r requirements.txt
```

3ï¸âƒ£ **Entrenar el pipeline**

```bash
python src/pipeline/training_pipeline.py
```

4ï¸âƒ£ **Ejecutar app Streamlit**

```bash
streamlit run app.py
```

---

## ğŸ§ª **12. Usar el modelo desde Python**

```python
from src.pipeline.predict_pipeline import CustomData, PredictPipeline

data = CustomData(
    crim=0.1,
    zn=10,
    indus=5.0,
    nox=0.5,
    rm=6.5,
    edad=60,
    dis=4.0,
    rad=4,
    impuesto=300,
    ptratio=18,
    negro=390,
    lstat=12
)

df = data.get_data_as_dataframe()
pred = PredictPipeline().predict(df)

print(pred[0])
```
---

## ğŸš€ **13. Mejoras futuras**

* Despliegue en Streamlit Cloud / Render / Hugging Face
* Explicabilidad del modelo (SHAP)
* API REST con FastAPI
* MLflow para tracking de experimentos
* ValidaciÃ³n de inputs con Pydantic


## âœ… **14. IntegraciÃ³n continua (CI) con GitHub Actions**

Este repositorio incluye un workflow de GitHub Actions (`.github/workflows/ci.yml`) que ejecuta automÃ¡ticamente:

- InstalaciÃ³n de dependencias
- RevisiÃ³n de estilo de cÃ³digo:
  - `isort` (orden de imports)
  - `black` (formato de cÃ³digo)
  - `flake8` (linting)
- Tests unitarios con `pytest`

El workflow se ejecuta en cada **push** y **pull request** a la rama `main`, verificando que:

- El cÃ³digo siga estÃ¡ndares de calidad
- Los tests pasen correctamente
- El proyecto sea estable antes de mezclar cambios

Esto imita un entorno real de trabajo con **CI**.

![CI](https://github.com/bryanOsmar07/02_Regression_HousePricePrediction/actions/workflows/ci.yml/badge.svg)

ğŸ“¦ **InstalaciÃ³n de dependencias de desarrollo**

```bash
pip install -r requirements-dev.txt

black
flake8
isort
pytest
pre-commit
```

ğŸª **Pre-commit Hooks**

Para garantizar un cÃ³digo limpio en cada commit:

```bash
pre-commit install
```
Ejecutar manualmente sobre todos los archivos:

```bash
pre-commit run --all-files
```

Estos hooks aseguran que no puedas hacer commit si el cÃ³digo no cumple estÃ¡ndares.


## ğŸ§ª **15. Pruebas unitarias (Pytest)**

El proyecto incluye tests para:

* Ingesta de datos
* TransformaciÃ³n
* Entrenamiento de modelo
* Pipeline de predicciÃ³n
* Funciones utilitarias

Para ejecutar:

```bash
pytest -v
```

## ğŸš€ **16. IntegraciÃ³n continua (CI/CD) con GitHub Actions**

Este repositorio usa un workflow en:

```bash
.github/workflows/ci.yml
```

El workflow se ejecuta automÃ¡ticamente en cada push y pull request a main.

Â¿QuÃ© valida?

âœ” InstalaciÃ³n del proyecto

âœ” Linting (black, isort, flake8)

âœ” Pruebas unitarias con pytest

âœ” Garantiza que el proyecto no se rompa

Badge (opcional)

```md
![CI](https://github.com/bryanOsmar07/02_Regression_HousePricePrediction/actions/workflows/ci.yml/badge.svg)
```

## ğŸ–¥ï¸ **17. Ejecutar la app sin usar terminal**

âœ” OpciÃ³n 1 â€” Archivo .bat (Windows)

Crear run_app.bat:

```bat
@echo off
cd /d %~dp0

call venv\Scripts\activate

streamlit run app.py

pause
```

## ğŸ **18. Estado del proyecto**

âœ” End-to-end pipeline

âœ” Modelo XGBoost tunado

âœ” Linting / Testing / Pre-commit

âœ” CI/CD con GitHub Actions

âœ” App Streamlit totalmente funcional

âœ” Ejecutable con un clic

ğŸ‘¨â€ğŸ’» Autor

Proyecto desarrollado por Brayan Osmar Quispe Montoya
Data Scientist
2025